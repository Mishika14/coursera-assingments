{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afc2a547",
   "metadata": {},
   "source": [
    "## #Pre-Graded Assingment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e942a5",
   "metadata": {},
   "source": [
    "### INTRODUCTION\n",
    "\n",
    "This assingment introduces  you to multiple data science tools, and in this final project, you will use Jupyterlite Notebook, one of the easiest tools to share publicly. \n",
    "\n",
    "Leveraging Jupyterlite Notebook on Skills Network labs, you will create your Jupyterlite Notebook (in English) and share it via a public GitHub link.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e3f112",
   "metadata": {},
   "source": [
    "### Data Science Languages\n",
    "\n",
    "1. **Python:** Python is one of the most widely used programming languages in data science. It offers a rich ecosystem of libraries and tools for data analysis, machine learning, and data visualization, including NumPy, pandas, scikit-learn, and Matplotlib.\n",
    "\n",
    "2. **R:** R is a programming language and environment designed specifically for statistical analysis and data visualization. It has a strong community of statisticians and data scientists who develop packages for various data science tasks.\n",
    "\n",
    "3. **SQL:** SQL (Structured Query Language) is essential for working with databases. Data scientists often use SQL to query and manipulate data in relational databases, such as PostgreSQL, MySQL, and SQLite.\n",
    "\n",
    "4. **Julia:** Julia is a high-performance programming language for technical computing. It's gaining popularity in data science for its speed and ease of use for numerical and scientific computing.\n",
    "\n",
    "5. **Scala:** Scala is often used in conjunction with Apache Spark for big data processing. It's a functional programming language that can handle large-scale data analysis.\n",
    "\n",
    "6. **Java:** Java is commonly used for building data science applications and tools. It's also used in big data technologies like Hadoop.\n",
    "\n",
    "7. **SAS:** SAS (Statistical Analysis System) is a software suite often used in business analytics and biostatistics for data analysis and visualization.\n",
    "\n",
    "8. **MATLAB:** MATLAB is a proprietary programming language and environment used in various scientific and engineering fields, including data analysis.\n",
    "\n",
    "9. **JavaScript:** For web-based data visualizations and interactive dashboards, JavaScript, along with libraries like D3.js, is commonly used.\n",
    "\n",
    "10. **C/C++:** While less common, C and C++ can be used for data analysis tasks that require low-level optimization, or when interfacing with libraries written in these languages.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c57d15",
   "metadata": {},
   "source": [
    "### Data Science Libraries\n",
    "\n",
    "1. **NumPy:** A fundamental library for numerical operations in Python. It provides support for arrays and matrices, making it essential for scientific computing and data manipulation.\n",
    "\n",
    "2. **pandas:** A versatile data manipulation library for Python. It offers data structures and functions for working with structured data, such as data frames and time series.\n",
    "\n",
    "3. **scikit-learn:** A machine learning library for Python that provides simple and efficient tools for data analysis and modeling. It includes various algorithms for classification, regression, clustering, and more.\n",
    "\n",
    "4. **Matplotlib:** A popular data visualization library for Python. It allows you to create a wide range of static, animated, or interactive plots and graphs.\n",
    "\n",
    "5. **Seaborn:** Built on top of Matplotlib, Seaborn is another Python data visualization library that simplifies the creation of aesthetically pleasing statistical graphics.\n",
    "\n",
    "6. **TensorFlow:** An open-source machine learning framework developed by Google for tasks like deep learning and neural networks.\n",
    "\n",
    "7. **Keras:** Keras is an API that can run on top of TensorFlow, Theano, or other deep learning frameworks. It simplifies the process of building and training deep neural networks.\n",
    "\n",
    "8. **PyTorch:** An open-source deep learning framework developed by Facebook's AI Research lab. It's known for its dynamic computation graph, making it more flexible for certain applications.\n",
    "\n",
    "9. **SciPy:** An open-source library for mathematics, science, and engineering that builds on the capabilities of NumPy. It includes functions for optimization, integration, interpolation, and more.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd399a4",
   "metadata": {},
   "source": [
    "### Data Science Tools\n",
    "\n",
    "| Tool                  | Description                                                |\n",
    "|-----------------------|------------------------------------------------------------|\n",
    "| **Jupyter Notebook**  | An open-source web application for creating and sharing documents that contain live code, equations, visualizations, and narrative text. |\n",
    "| **RStudio**           | An integrated development environment (IDE) for the R programming language, designed for data analysis and visualization. |\n",
    "| **Spyder**            | A powerful Python IDE for scientific computing with features like an interactive console and variable explorer. |\n",
    "| **Visual Studio Code**| A versatile code editor with extensions for data science, machine learning, and various programming languages. |\n",
    "| **Tableau**           | A data visualization tool that simplifies the creation of interactive and shareable dashboards and reports. |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7de1772",
   "metadata": {},
   "source": [
    "### Arithmetic Expression Examples\n",
    "\n",
    "Arithmetic expressions are fundamental mathematical operations that involve numbers, operators, and calculations. They are used in various fields, including mathematics, science, and computer programming. In data science, arithmetic expressions are often used to manipulate and process numerical data. Here are some common examples of arithmetic expressions:\n",
    "\n",
    "1. **Addition (+):** The addition operator combines two or more numbers to find their sum. For example:\n",
    "   - `3 + 5 = 8`\n",
    "   - `12.5 + 7.3 = 19.8`\n",
    "\n",
    "2. **Subtraction (-):** The subtraction operator finds the difference between two numbers. For example:\n",
    "   - `10 - 4 = 6`\n",
    "   - `23.7 - 8.2 = 15.5`\n",
    "\n",
    "3. **Multiplication (*):** The multiplication operator calculates the product of two or more numbers. For example:\n",
    "   - `6 * 9 = 54`\n",
    "   - `2.5 * 4.8 = 12`\n",
    "\n",
    "4. **Division (/):** The division operator divides one number by another to find the quotient. For example:\n",
    "   - `20 / 4 = 5`\n",
    "   - `15.6 / 3 = 5.2`\n",
    "\n",
    "5. **Exponentiation (** or ^):** The exponentiation operator raises a number to a specified power. For example:\n",
    "   - `2 ** 3 = 8` (2 raised to the power of 3)\n",
    "   - `5^2 = 25` (5 squared)\n",
    "\n",
    "6. **Modulo (%):** The modulo operator returns the remainder when one number is divided by another. For example:\n",
    "   - `15 % 7 = 1` (remainder when 15 is divided by 7)\n",
    "   - `10 % 3 = 1` (remainder when 10 is divided by 3)\n",
    "\n",
    "Arithmetic expressions can become more complex when combined with parentheses to control the order of operations. These expressions are a fundamental part of data manipulation, calculation, and analysis in various data science tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1397c9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiplication = 15\n",
      "addition = 8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "number1 = 5\n",
    "number2 = 3\n",
    "\n",
    "result_multiply = number1 * number2\n",
    "print(f\"multiplication = {result_multiply}\")\n",
    "result_add = number1 + number2\n",
    "print(f\"addition = {result_add}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d0c4292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 minutes is equal to 2.5 hours\n"
     ]
    }
   ],
   "source": [
    "\n",
    "minutes = 150\n",
    "\n",
    "hours = minutes / 60\n",
    "\n",
    "print(f\"{minutes} minutes is equal to {hours} hours\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bd8a49",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "\n",
    "In a data science project, it's essential to have clear objectives to guide your work and ensure that you're addressing the key goals of the project. Objectives help define the scope and purpose of your analysis. Here are some common data science objectives:\n",
    "\n",
    "1. **Data Exploration and Understanding:** Gain insights into the dataset by exploring and understanding the data's characteristics, structure, and patterns.\n",
    "\n",
    "2. **Data Cleaning and Preprocessing:** Prepare the data by handling missing values, outliers, and formatting issues, making it suitable for analysis.\n",
    "\n",
    "3. **Descriptive Analysis:** Generate summary statistics, visualizations, and reports to describe and summarize the data.\n",
    "\n",
    "4. **Predictive Modeling:** Build machine learning models to make predictions, classifications, or recommendations based on the data.\n",
    "\n",
    "5. **Hypothesis Testing:** Test hypotheses and conduct statistical analyses to answer specific questions about the data.\n",
    "\n",
    "6. **Feature Engineering:** Create new features or modify existing ones to improve model performance.\n",
    "\n",
    "7. **Model Evaluation:** Assess model performance using metrics like accuracy, precision, recall, and F1-score.\n",
    "\n",
    "8. **Data Visualization:** Create informative and insightful data visualizations to communicate findings and insights.\n",
    "\n",
    "9. **Report and Presentation:** Prepare reports, presentations, or dashboards to share the results and findings with stakeholders.\n",
    "\n",
    "10. **Deployment and Automation:** If applicable, deploy models or solutions into production and automate data pipelines.\n",
    "\n",
    "11. **Ethical Considerations:** Ensure that the data science project adheres to ethical and legal guidelines, particularly in terms of privacy and bias.\n",
    "\n",
    "12. **Business Impact:** Measure and communicate the business impact of the data science project, such as cost savings, revenue increase, or process improvement.\n",
    "\n",
    "13. **Continuous Learning and Improvement:** Continuously learn and adapt to new techniques, tools, and methodologies to improve data science skills and stay up-to-date.\n",
    "\n",
    "Having well-defined objectives is critical for project success and helps in managing time and resources effectively while delivering meaningful insights and solutions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41cfb09",
   "metadata": {},
   "source": [
    "### Author's name-Mishika Soni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fa77ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
